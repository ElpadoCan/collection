name: test backoffice and build docs

on: push

concurrency: test

env:
  S3_HOST: ${{vars.S3_HOST}}
  S3_BUCKET: ${{vars.S3_TEST_BUCKET}} # testing!
  S3_FOLDER: ${{vars.S3_TEST_FOLDER}} # testing!
  S3_TEST_BUCKET: ${{vars.S3_TEST_BUCKET}}
  S3_TEST_FOLDER: ${{vars.S3_TEST_FOLDER}}
  S3_PYTEST_FOLDER: ${{vars.S3_PYTEST_FOLDER}}
  ZENODO_URL: ${{vars.ZENODO_TEST_URL}} # testing!
  ZENODO_TEST_URL: ${{vars.ZENODO_TEST_URL}}

  S3_ACCESS_KEY_ID: ${{secrets.S3_ACCESS_KEY_ID}}
  S3_SECRET_ACCESS_KEY: ${{secrets.S3_SECRET_ACCESS_KEY}}
  ZENODO_API_ACCESS_TOKEN: ${{secrets.ZENODO_TEST_API_ACCESS_TOKEN}} # testing!
  ZENODO_TEST_API_ACCESS_TOKEN: ${{secrets.ZENODO_TEST_API_ACCESS_TOKEN}}

  TEST_PACKAGE_ID: ${{vars.TEST_PACKAGE_ID}}
  TEST_PACKAGE_URL: ${{vars.TEST_PACKAGE_URL}}

jobs:
  initial-cleanup:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip" # caching pip dependencies
      - run: pip install .
      - run: backoffice wipe --bucket "${{vars.S3_TEST_BUCKET}}" --prefix "${{vars.S3_TEST_FOLDER}}"

  test-stage-wf:
    needs: initial-cleanup
    uses: bioimage-io/collection/.github/workflows/stage_call.yaml@main
    with:
      resource_id: ${{vars.TEST_PACKAGE_ID}} # testing!
      package_url: ${{vars.TEST_PACKAGE_URL}} # testing!
      S3_HOST: ${{vars.S3_HOST}}
      S3_BUCKET: ${{vars.S3_TEST_BUCKET}} # testing!
      S3_FOLDER: ${{vars.S3_TEST_FOLDER}}/ci # testing!
    secrets: inherit

  test-publish-wf:
    needs: test-stage-wf
    uses: bioimage-io/collection/.github/workflows/publish_call.yaml@main
    with:
      resource_id: ${{vars.TEST_PACKAGE_ID}} # testing!
      stage_number: 1
      reviewer: test
      S3_HOST: ${{vars.S3_HOST}}
      S3_BUCKET: ${{vars.S3_TEST_BUCKET}} # testing!
      S3_FOLDER: ${{vars.S3_TEST_FOLDER}}/ci # testing!
    secrets: inherit

  test-generate-collection-json-wf:
    needs: test-publish-wf
    uses: bioimage-io/collection/.github/workflows/generate_collection_json_call.yaml@main
    with:
      S3_HOST: ${{vars.S3_HOST}}
      S3_BUCKET: ${{vars.S3_TEST_BUCKET}} # testing!
      S3_FOLDER: ${{vars.S3_TEST_FOLDER}}/ci # testing!
    secrets: inherit

  test-backup-wf:
    needs: test-generate-collection-json-wf
    uses: bioimage-io/collection/.github/workflows/backup_call.yaml@main
    with:
      S3_HOST: ${{vars.S3_HOST}}
      S3_BUCKET: ${{vars.S3_TEST_BUCKET}} # testing!
      S3_FOLDER: ${{vars.S3_TEST_FOLDER}}/ci # testing!
      ZENODO_URL: ${{vars.ZENODO_TEST_URL}} # testing!
    secrets: inherit

  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip" # caching pip dependencies
      - run: pip install .[dev]
      - run: black . --check
      - run: pyright -p pyproject.toml
      - run: pytest
      - name: export documentation
        run: pdoc bioimageio_collection_backoffice -o ./docs
      - run: cp README.md ./docs/  # TODO: do not use upload-pages-artifact, because the README.md somehow doesn't make it, compare to https://github.com/bioimage-io/spec-bioimage-io/blob/275cb4266e5661f7315165e7c069d6f30dd5651d/.github/workflows/build.yml#L74 which works
      - uses: actions/upload-pages-artifact@v3
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          path: docs/

  deploy_docs:
    needs: build
    if: ${{ github.ref == 'refs/heads/main' }}
    # Grant GITHUB_TOKEN the permissions required to make a Pages deployment
    permissions:
      pages: write # to deploy to Pages
      id-token: write # to verify the deployment originates from an appropriate source

    # Deploy to the github-pages environment
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    runs-on: ubuntu-latest
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
